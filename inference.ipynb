{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3137b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"300000\", padding_side='left')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"300000\").to(\"cuda:1\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda:2\")\n",
    "    \n",
    "## utility functions ##\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def to_data(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cpu()\n",
    "    return x.data.numpy()\n",
    "\n",
    "def to_var(x):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.Tensor(x).to(\"cuda:2\")\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.to(\"cuda:2\")\n",
    "    return x\n",
    "\n",
    "def display_dialog_history(dialog_hx):\n",
    "    for j, line in enumerate(dialog_hx):\n",
    "        msg = tokenizer.decode(line)\n",
    "        if j %2 == 0:\n",
    "            print(\">> User: \"+ msg)\n",
    "        else:\n",
    "            print(\"Bot: \"+msg)\n",
    "            print()\n",
    "\n",
    "def generate_next(bot_input_ids, do_sample=True, top_k=10, top_p=.92,\n",
    "                  max_length=1000, pad_token=tokenizer.eos_token_id):\n",
    "    full_msg = model.generate(bot_input_ids, do_sample=True,\n",
    "                                              top_k=top_k, top_p=top_p, \n",
    "                                              max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
    "    msg = to_data(full_msg.detach()[0])[bot_input_ids.shape[-1]:]\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4852256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Fact 1: i am 64 years old but feel quite young.\n",
      ">> Fact 2: i try to eat healthy but limit mcdonalds to once a week.\n",
      ">> Fact 3: i regret working as a doctor for the last 20 years.\n",
      ">> Fact 4: my secret hobby is making self-help youtube videos.\n",
      ">> Fact 5: i've been to spain many times and wish i could go again\n"
     ]
    }
   ],
   "source": [
    "# get personality facts for conversation\n",
    "personas = []\n",
    "for i in range(5):\n",
    "    response = input(\">> Fact %d: \"%(i+1))+ tokenizer.eos_token\n",
    "    personas.append(response)\n",
    "personas = tokenizer.encode(''.join(['<|p2|>'] + personas + ['<|sep|>'] + ['<|start|>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adb3548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User: hi how are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: 64 years old and feel quite young. yet i'm young.\n",
      ">> User: I'm 24 years old. and I'm student. what is your job?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  doctor, but i regret working as a doctor for the last 20 years.\n",
      ">> User: why? I think that is cool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: yeah, but i wanted to go again. but i've to limit mcdonalds. i just watch videos for fun.\n",
      ">> User: I love youtube! what is your favorite?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  self spirited help videos. what do you like?\n",
      ">> User: I like dancing video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  blah blah blah. blah.\n",
      ">> User: haha do you like travel?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  i've been to spain many times. but i wish i could go again.\n",
      ">> User: I want to go spain too! wow you are so nice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  ops what do you do?\n",
      ">> User: I'm student\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  whats your favorite class?\n"
     ]
    }
   ],
   "source": [
    "# converse for 8 turns\n",
    "dialog_hx = []\n",
    "for step in range(8):\n",
    "    # encode the user input\n",
    "    user_inp = tokenizer.encode(input(\">> User: \") + tokenizer.eos_token)\n",
    "    # append to the chat history\n",
    "    dialog_hx.append(user_inp)\n",
    "        \n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    bot_input_ids = to_var([personas + flatten(dialog_hx)]).long()\n",
    "    msg = generate_next(bot_input_ids)\n",
    "    dialog_hx.append(msg)\n",
    "    print(\"Bot: {}\".format(tokenizer.decode(msg, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8cb70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Fact 1: i read twenty books a year.\n",
      ">> Fact 2: i'm a stunt double as my second job.\n",
      ">> Fact 3: i only eat kosher.\n",
      ">> Fact 4: i was raised in a single parent household.\n",
      ">> Fact 5: I love listen to music\n"
     ]
    }
   ],
   "source": [
    "# get personality facts for conversation\n",
    "personas = []\n",
    "for i in range(5):\n",
    "    response = input(\">> Fact %d: \"%(i+1))+ tokenizer.eos_token\n",
    "    personas.append(response)\n",
    "personas = tokenizer.encode(''.join(['<|p2|>'] + personas + ['<|sep|>'] + ['<|start|>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a633fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User: hi how are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: good. i am an avid reader. i have been reading for over 20 years.\n",
      ">> User: I'm student I also like read books. what is your favorite food?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  i only eat healthy foods.\n",
      ">> User: do you like salad?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  i only eat healthy foods.\n",
      ">> User: I see. I like to listen music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  do you work?\n",
      ">> User: yes I work at lab. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  what is your favorite band?\n",
      ">> User: I love band wul. what do you like?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  i like whos your favorite band?\n",
      ">> User: what is your favorite band?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: IBLE f bieber. what is your favorite food?\n",
      ">> User: I love orange juice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: \n"
     ]
    }
   ],
   "source": [
    "# converse for 8 turns\n",
    "dialog_hx = []\n",
    "for step in range(8):\n",
    "    # encode the user input\n",
    "    user_inp = tokenizer.encode(input(\">> User: \") + tokenizer.eos_token)\n",
    "    # append to the chat history\n",
    "    dialog_hx.append(user_inp)\n",
    "        \n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    bot_input_ids = to_var([personas + flatten(dialog_hx)]).long()\n",
    "    msg = generate_next(bot_input_ids)\n",
    "    dialog_hx.append(msg)\n",
    "    print(\"Bot: {}\".format(tokenizer.decode(msg, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c715529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
